{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022aa06b",
   "metadata": {},
   "source": [
    "# Dementia Prediction Model Notebook\n",
    "This notebook predicts dementia status using clinical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f424243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    GroupShuffleSplit,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65f47c",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "Read the dementia prediction dataset from CSV into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a750ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dementia Prediction Dataset.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0308b",
   "metadata": {},
   "source": [
    "## Inspect raw data\n",
    "Show the first rows to understand the columns and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc021634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>NACCADC</th>\n",
       "      <th>PACKET</th>\n",
       "      <th>FORMVER</th>\n",
       "      <th>VISITMO</th>\n",
       "      <th>VISITDAY</th>\n",
       "      <th>VISITYR</th>\n",
       "      <th>NACCVNUM</th>\n",
       "      <th>NACCAVST</th>\n",
       "      <th>NACCNVST</th>\n",
       "      <th>...</th>\n",
       "      <th>NPATGAM1</th>\n",
       "      <th>NPATGAM2</th>\n",
       "      <th>NPATGAM3</th>\n",
       "      <th>NPATGAM4</th>\n",
       "      <th>NPATGAM5</th>\n",
       "      <th>NPATGFRN</th>\n",
       "      <th>NPATGFR1</th>\n",
       "      <th>NPATGFR2</th>\n",
       "      <th>NPATGFR3</th>\n",
       "      <th>NPATGFR4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>186</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NACC003487</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACC004352</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACC004687</td>\n",
       "      <td>186</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195191</th>\n",
       "      <td>NACC998475</td>\n",
       "      <td>9661</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195192</th>\n",
       "      <td>NACC999391</td>\n",
       "      <td>9661</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195193</th>\n",
       "      <td>NACC999391</td>\n",
       "      <td>9661</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195194</th>\n",
       "      <td>NACC999391</td>\n",
       "      <td>9661</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195195</th>\n",
       "      <td>NACC999420</td>\n",
       "      <td>9661</td>\n",
       "      <td>I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195196 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            NACCID  NACCADC PACKET  FORMVER  VISITMO  VISITDAY  VISITYR  \\\n",
       "0       NACC002909      186      I      3.0       12        28     2022   \n",
       "1       NACC002909      186      F      3.0        1        23     2024   \n",
       "2       NACC003487      186      I      3.0       11        15     2023   \n",
       "3       NACC004352      186      I      3.0       10         5     2021   \n",
       "4       NACC004687      186      I      3.0       11        14     2022   \n",
       "...            ...      ...    ...      ...      ...       ...      ...   \n",
       "195191  NACC998475     9661      F      2.0       11         6     2008   \n",
       "195192  NACC999391     9661      I      1.0        3         2     2006   \n",
       "195193  NACC999391     9661      F      1.0        5        17     2007   \n",
       "195194  NACC999391     9661      F      2.0        3        27     2008   \n",
       "195195  NACC999420     9661      I      3.0        1        25     2024   \n",
       "\n",
       "        NACCVNUM  NACCAVST  NACCNVST  ...  NPATGAM1  NPATGAM2  NPATGAM3  \\\n",
       "0              1         2         2  ...        -4        -4        -4   \n",
       "1              2         2         2  ...        -4        -4        -4   \n",
       "2              1         1         1  ...        -4        -4        -4   \n",
       "3              1         1         1  ...        -4        -4        -4   \n",
       "4              1         1         1  ...        -4        -4        -4   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "195191         3         3         3  ...        -4        -4        -4   \n",
       "195192         1         3         3  ...        -4        -4        -4   \n",
       "195193         2         3         3  ...        -4        -4        -4   \n",
       "195194         3         3         3  ...        -4        -4        -4   \n",
       "195195         1         1         1  ...        -4        -4        -4   \n",
       "\n",
       "        NPATGAM4  NPATGAM5  NPATGFRN  NPATGFR1  NPATGFR2  NPATGFR3  NPATGFR4  \n",
       "0             -4        -4        -4        -4        -4        -4        -4  \n",
       "1             -4        -4        -4        -4        -4        -4        -4  \n",
       "2             -4        -4        -4        -4        -4        -4        -4  \n",
       "3             -4        -4        -4        -4        -4        -4        -4  \n",
       "4             -4        -4        -4        -4        -4        -4        -4  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "195191        -4        -4        -4        -4        -4        -4        -4  \n",
       "195192        -4        -4        -4        -4        -4        -4        -4  \n",
       "195193        -4        -4        -4        -4        -4        -4        -4  \n",
       "195194        -4        -4        -4        -4        -4        -4        -4  \n",
       "195195        -4        -4        -4        -4        -4        -4        -4  \n",
       "\n",
       "[195196 rows x 1024 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab65dc1",
   "metadata": {},
   "source": [
    "## Target distribution\n",
    "Check how many visits are labeled as demented or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83e3756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEMENTED\n",
       "0    137606\n",
       "1     57590\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.DEMENTED.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c08010",
   "metadata": {},
   "source": [
    "## Select feature groups\n",
    "Define demographic, health history, and family history columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 demographics columns\n",
    "a1_cols = [\n",
    "    \"NACCAGE\", \"SEX\", \"EDUC\", \"RACE\", \"RACESEC\", \"RACETER\",\n",
    "    \"PRIMLANG\", \"MARISTAT\", \"RESIDENC\", \"NACCLIVS\",\n",
    "    \"INDEPEND\", \"HANDED\", \"NACCREFR\", \"NACCREAS\",\n",
    "]\n",
    "\n",
    "# A5 self-reported health history columns\n",
    "a5_cols = [\n",
    "    \"CVHATT\", \"HATTMULT\", \"CVAFIB\", \"CVANGIO\", \"CVBYPASS\", \"CVPACDEF\", \"CVPACE\",\n",
    "    \"CVCHF\", \"CVANGINA\", \"CVHVALVE\", \"CVOTHR\",\n",
    "    \"CBSTROKE\", \"STROKMUL\", \"CBTIA\", \"TIAMULT\",\n",
    "    \"DIABETES\", \"DIABTYPE\", \"HYPERTEN\", \"HYPERCHO\",\n",
    "    \"PD\", \"SEIZURES\", \"TBI\",\n",
    "    \"APNEA\", \"INSOMN\", \"DEP2YRS\", \"PTSD\", \"BIPOLAR\", \"ANXIETY\",\n",
    "    \"TOBAC30\", \"TOBAC100\", \"SMOKYRS\", \"PACKSPER\", \"QUITSMOK\",\n",
    "    \"ALCOCCAS\", \"ALCFREQ\", \"ABUSOTHR\",\n",
    "    \"NACCBMI\", 'HEIGHT', 'WEIGHT','THYROID','B12DEF','ARTHRIT','INCONTU'\n",
    "]\n",
    "\n",
    "# A3 family history columns\n",
    "a3_cols = [\"NACCFAM\", \"NACCMOM\", \"NACCDAD\"]\n",
    "\n",
    "# Combine all columns\n",
    "selected_cols = a1_cols + a5_cols + a3_cols\n",
    "\n",
    "# Define target column\n",
    "target_col=\"DEMENTED\"\n",
    "\n",
    "# Extract only those columns\n",
    "df_sel = df[selected_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce265f5",
   "metadata": {},
   "source": [
    "## Define cleaning helpers\n",
    "Create small functions to clean age, education, and A5 flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_age(x):\n",
    "    return np.nan if x in [888, 999, 995, 996, 997] else x\n",
    "\n",
    "def clean_educ(x):\n",
    "    return np.nan if x == 99 else x\n",
    "\n",
    "def a5_to_flag(s):\n",
    "    \"\"\"\n",
    "    A5 coding:\n",
    "    0 = No, 1 = Recent/active, 2 = Remote/inactive,\n",
    "    9 = Unknown, -4 = Not available\n",
    "    Convert (1) -> 1, (2) -> 2, (0) -> 0, unknown -> NaN.\n",
    "    \"\"\"\n",
    "    return s.replace({1:1, 2:2, 0:0, 9:np.nan, -4:np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378879b",
   "metadata": {},
   "source": [
    "## Build final feature table\n",
    "Engineer and encode features for modeling, including BMI and flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final feature dataframe\n",
    "df_final = pd.DataFrame(index=df_sel.index)\n",
    "\n",
    "# Age\n",
    "df_final[\"AGE\"] = df_sel[\"NACCAGE\"].apply(clean_missing_age)\n",
    "\n",
    "# Basic demographics\n",
    "df_final[\"SEX\"] = df_sel[\"SEX\"]\n",
    "df_final[\"EDUC_YEARS\"] = df_sel[\"EDUC\"].apply(clean_educ)\n",
    "df_final[\"HANDED\"] = df_sel[\"HANDED\"]\n",
    "df_final[\"INDEPEND\"] = df_sel[\"INDEPEND\"]\n",
    "df_final[\"NACCLIVS\"] = df_sel[\"NACCLIVS\"]\n",
    "\n",
    "# Language\n",
    "df_final[\"PRIMLANG\"] = df_sel[\"PRIMLANG\"]\n",
    "df_final[\"IS_NON_ENGLISH_HOME\"] = (df_sel[\"PRIMLANG\"] != 1).astype(int)\n",
    "\n",
    "# Marital status (one-hot)\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"MARISTAT\"], prefix=\"MARITAL\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "# Residence type (one-hot)\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"RESIDENC\"], prefix=\"RESIDENCE\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "# Race\n",
    "df_final[\"RACE\"] = df_sel[\"RACE\"]\n",
    "df_final[\"IS_MULTIRACIAL\"] = (\n",
    "    df_sel[\"RACESEC\"].isin([1,2,3,4,5,50]) | \n",
    "    df_sel[\"RACETER\"].isin([1,2,3,4,5,50])\n",
    ").astype(int)\n",
    "df_final[\"RACE_OTHER\"] = (df_sel[\"RACE\"] == 50).astype(int)\n",
    "\n",
    "# One-hot encode primary race\n",
    "df_final = pd.concat([df_final,\n",
    "                      pd.get_dummies(df_sel[\"RACE\"], prefix=\"RACE\", dtype=int)],\n",
    "                     axis=1)\n",
    "\n",
    "\n",
    "# A5 variables as flag features\n",
    "\n",
    "for col in a5_cols:\n",
    "    \n",
    "    if col == \"DIABTYPE\":\n",
    "        # Keep DIABTYPE as a numeric category (optional)\n",
    "        df_final[\"DIABTYPE\"] = df_sel[\"DIABTYPE\"].replace({9:np.nan, -4:np.nan})\n",
    "    else:\n",
    "        df_final[col + \"_FLAG\"] = a5_to_flag(df_sel[col])\n",
    "\n",
    "# Extra smoking-related features\n",
    "df_final[\"SMOKED_100PLUS\"] = df_sel[\"TOBAC100\"].replace({0:0, 1:1, 9:np.nan, -4:np.nan})\n",
    "\n",
    "df_final[\"SMOKED_LAST_30D\"] = df_sel[\"TOBAC30\"].replace({0:0,1:1, 9:np.nan, -4:np.nan})\n",
    "\n",
    "# Body mass index (BMI)\n",
    "df_final[\"BMI\"] = df_sel[\"NACCBMI\"].replace({888.8:np.nan,-4:np.nan})\n",
    "\n",
    "# Fill missing BMI by calculating BMI where HEIGHT and WEIGHT exist.\n",
    "df_sel[\"HEIGHT\"] = df_sel[\"HEIGHT\"].replace({88.8:np.nan,-4:np.nan})\n",
    "df_sel[\"WEIGHT\"] = df_sel[\"WEIGHT\"].replace({888.0:np.nan,-4:np.nan})\n",
    "\n",
    "# BMI formula: (weight in lbs × 703) / (height in inches)^2\n",
    "df_final.loc[\n",
    "    df_final[\"BMI\"].isna() &\n",
    "    df_sel[\"HEIGHT\"].notna() &\n",
    "    df_sel[\"WEIGHT\"].notna(),\n",
    "    \"BMI\"\n",
    " ] =  (df_sel[\"WEIGHT\"] * 703) / (df_sel[\"HEIGHT\"] ** 2)\n",
    "\n",
    "# A3 family history flags (optional but included)\n",
    "\n",
    "for col in a3_cols:\n",
    "    df_final[col + \"_FLAG\"] = df_sel[col].replace({0:0,1:1,9:np.nan,-4:np.nan})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde9b19",
   "metadata": {},
   "source": [
    "## Define X and y\n",
    "Create the feature matrix X and target vector y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31aca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[target_col]\n",
    "X=df_final.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a87822",
   "metadata": {},
   "source": [
    "## Check shapes\n",
    "Confirm the dimensions of X and y before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca51ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (195196, 79)\n",
      "y: (195196,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUC_YEARS</th>\n",
       "      <th>HANDED</th>\n",
       "      <th>INDEPEND</th>\n",
       "      <th>NACCLIVS</th>\n",
       "      <th>PRIMLANG</th>\n",
       "      <th>IS_NON_ENGLISH_HOME</th>\n",
       "      <th>MARITAL_1</th>\n",
       "      <th>MARITAL_2</th>\n",
       "      <th>...</th>\n",
       "      <th>THYROID_FLAG</th>\n",
       "      <th>B12DEF_FLAG</th>\n",
       "      <th>ARTHRIT_FLAG</th>\n",
       "      <th>INCONTU_FLAG</th>\n",
       "      <th>SMOKED_100PLUS</th>\n",
       "      <th>SMOKED_LAST_30D</th>\n",
       "      <th>BMI</th>\n",
       "      <th>NACCFAM_FLAG</th>\n",
       "      <th>NACCMOM_FLAG</th>\n",
       "      <th>NACCDAD_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195191</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195192</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195193</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195194</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195195</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195196 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  SEX  EDUC_YEARS  HANDED  INDEPEND  NACCLIVS  PRIMLANG  \\\n",
       "0        70    1        16.0       2         1         4         1   \n",
       "1        71    1        16.0       2         1         2         1   \n",
       "2        66    1        16.0       2         1         2         1   \n",
       "3        63    2        16.0       2         2         2         2   \n",
       "4        77    1        12.0       2         1         1         1   \n",
       "...     ...  ...         ...     ...       ...       ...       ...   \n",
       "195191   72    2        13.0       2         2         4         1   \n",
       "195192   87    1        13.0       2         1         1         1   \n",
       "195193   89    1        13.0       2         3         1         1   \n",
       "195194   89    1        13.0       2         3         1         1   \n",
       "195195   61    2        18.0       1         1         3         1   \n",
       "\n",
       "        IS_NON_ENGLISH_HOME  MARITAL_1  MARITAL_2  ...  THYROID_FLAG  \\\n",
       "0                         0          1          0  ...           1.0   \n",
       "1                         0          1          0  ...           NaN   \n",
       "2                         0          1          0  ...           0.0   \n",
       "3                         1          1          0  ...           NaN   \n",
       "4                         0          0          0  ...           0.0   \n",
       "...                     ...        ...        ...  ...           ...   \n",
       "195191                    0          0          0  ...           0.0   \n",
       "195192                    0          0          1  ...           0.0   \n",
       "195193                    0          0          1  ...           0.0   \n",
       "195194                    0          0          1  ...           0.0   \n",
       "195195                    0          0          0  ...           0.0   \n",
       "\n",
       "        B12DEF_FLAG  ARTHRIT_FLAG  INCONTU_FLAG  SMOKED_100PLUS  \\\n",
       "0               0.0           0.0           1.0             0.0   \n",
       "1               NaN           NaN           NaN             NaN   \n",
       "2               0.0           0.0           0.0             0.0   \n",
       "3               NaN           NaN           NaN             0.0   \n",
       "4               0.0           0.0           0.0             0.0   \n",
       "...             ...           ...           ...             ...   \n",
       "195191          0.0           NaN           2.0             0.0   \n",
       "195192          1.0           NaN           1.0             1.0   \n",
       "195193          2.0           NaN           2.0             1.0   \n",
       "195194          1.0           NaN           1.0             1.0   \n",
       "195195          0.0           1.0           0.0             0.0   \n",
       "\n",
       "        SMOKED_LAST_30D   BMI  NACCFAM_FLAG  NACCMOM_FLAG  NACCDAD_FLAG  \n",
       "0                   0.0  32.4           1.0           0.0           0.0  \n",
       "1                   NaN  30.7           1.0           0.0           0.0  \n",
       "2                   0.0  23.7           0.0           0.0           0.0  \n",
       "3                   0.0   NaN           NaN           NaN           NaN  \n",
       "4                   0.0  19.0           NaN           0.0           0.0  \n",
       "...                 ...   ...           ...           ...           ...  \n",
       "195191              0.0   NaN           NaN           0.0           NaN  \n",
       "195192              0.0  26.8           NaN           0.0           0.0  \n",
       "195193              0.0  27.1           NaN           0.0           0.0  \n",
       "195194              0.0  25.5           NaN           0.0           0.0  \n",
       "195195              0.0  26.7           1.0           1.0           1.0  \n",
       "\n",
       "[195196 rows x 79 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8bcd0",
   "metadata": {},
   "source": [
    "## Participant overview\n",
    "Count how many unique participants and repeat visits exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a0e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique participants: 52537\n",
      "Participants with more than one visit: 35671\n"
     ]
    }
   ],
   "source": [
    "total = df[\"NACCID\"].nunique()\n",
    "duplicates = (df[\"NACCID\"].value_counts() > 1).sum()\n",
    "\n",
    "print(\"Total unique participants:\", total)\n",
    "print(\"Participants with more than one visit:\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e87f47",
   "metadata": {},
   "source": [
    "## Grouped train, validation, and test split\n",
    "Split visits by participant ID so the same person is not in multiple sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bda051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (136285, 79) (136285,)\n",
      "Validation: (29707, 79) (29707,)\n",
      "Test: (29204, 79) (29204,)\n",
      "\n",
      "Target distribution:\n",
      "Train:\n",
      " DEMENTED\n",
      "0    0.703313\n",
      "1    0.296687\n",
      "Name: proportion, dtype: float64\n",
      "Val:\n",
      " DEMENTED\n",
      "0    0.708385\n",
      "1    0.291615\n",
      "Name: proportion, dtype: float64\n",
      "Test:\n",
      " DEMENTED\n",
      "0    0.709184\n",
      "1    0.290816\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique participants:\n",
      "Train: 36775\n",
      "Val: 7881\n",
      "Test: 7881\n"
     ]
    }
   ],
   "source": [
    "# 1. Get participant IDs\n",
    "\n",
    "groups = df.loc[df.index, \"NACCID\"].reset_index(drop=True)\n",
    "\n",
    "# 2. First split: Train vs Temp (Val+Test)\n",
    "\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "\n",
    "train_idx, temp_idx = next(gss1.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "\n",
    "X_temp  = X.iloc[temp_idx]\n",
    "y_temp  = y.iloc[temp_idx]\n",
    "groups_temp = groups.iloc[temp_idx]\n",
    "\n",
    "\n",
    "# 3. Second split: Validation vs Test\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "\n",
    "val_idx, test_idx = next(gss2.split(X_temp, y_temp, groups=groups_temp))\n",
    "\n",
    "X_val  = X_temp.iloc[val_idx]\n",
    "y_val  = y_temp.iloc[val_idx]\n",
    "\n",
    "X_test = X_temp.iloc[test_idx]\n",
    "y_test = y_temp.iloc[test_idx]\n",
    "\n",
    "# 4. Print results\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(\"Train:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Val:\\n\",   y_val.value_counts(normalize=True))\n",
    "print(\"Test:\\n\",  y_test.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nUnique participants:\")\n",
    "print(\"Train:\", len(groups.iloc[train_idx].unique()))\n",
    "print(\"Val:\",   len(groups_temp.iloc[val_idx].unique()))\n",
    "print(\"Test:\",  len(groups_temp.iloc[test_idx].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b974d",
   "metadata": {},
   "source": [
    "## Evaluation helper\n",
    "Define a function to compute AUC and accuracy on validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model_name, model, X_val, y_val, X_test, y_test):\n",
    "    # Validation set evaluation\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = (val_proba > 0.5).astype(int)\n",
    "\n",
    "    val_auc = roc_auc_score(y_val, val_proba)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    # Test set evaluation\n",
    "    test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_proba > 0.5).astype(int)\n",
    "\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"====================================\")\n",
    "    print(f\"   {model_name} FINAL EVALUATION    \")\n",
    "    print(\"====================================\")\n",
    "    print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "    print(f\"Validation ACC: {val_acc:.4f}\")\n",
    "    print(\"------------------------------------\")\n",
    "    print(f\"Test AUC:       {test_auc:.4f}\")\n",
    "    print(f\"Test ACC:       {test_acc:.4f}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b28642",
   "metadata": {},
   "source": [
    "## Training helper\n",
    "Create a reusable function to run hyperparameter search and fit the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f22ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(base_estimator, param_grid, X_train, y_train, search_type=\"grid\", scoring=\"roc_auc\", cv=3, n_iter=40, verbose=2):\n",
    "    if search_type == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            estimator=base_estimator,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            verbose=verbose,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    elif search_type == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=base_estimator,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=n_iter,\n",
    "            scoring=scoring,\n",
    "            cv=cv,\n",
    "            verbose=verbose,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    base_params = base_estimator.get_params()\n",
    "    base_params.update(best_params)\n",
    "\n",
    "    final_model = base_estimator.__class__(\n",
    "        **base_params,\n",
    "    )\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    return final_model, search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14ded5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(model):\n",
    "    #Check Importance of columns \n",
    "    importance_df=pd.DataFrame({\n",
    "    'featura' : X.columns,\n",
    "    'importance' : model.feature_importances_\n",
    "    }).sort_values('importance',ascending=False)\n",
    "\n",
    "    return importance_df.head(10)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381125eb",
   "metadata": {},
   "source": [
    "## Random Forest model\n",
    "Tune and train a Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9db11e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "\n",
      "Best RF Params: {'class_weight': 'balanced', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best RF CV AUC: 0.9244191036452626\n",
      "\n",
      "Best RF Params: {'class_weight': 'balanced', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best RF CV AUC: 0.9244191036452626\n"
     ]
    }
   ],
   "source": [
    "rf_grid = {\n",
    "    \"n_estimators\": [200, 300],\n",
    "    \"max_depth\": [15, 20, 25],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "    }\n",
    "\n",
    "rf_model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "rf_final, grid_rf = train_model(\n",
    "    base_estimator=rf_model,\n",
    "    param_grid=rf_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    search_type=\"grid\",\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"\\nBest RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF CV AUC:\", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931cdbbc",
   "metadata": {},
   "source": [
    "## Evaluate Random Forest\n",
    "Evaluate performance of the tuned Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a3e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "   Random Forest FINAL EVALUATION    \n",
      "====================================\n",
      "Validation AUC: 0.9344\n",
      "Validation ACC: 0.9014\n",
      "------------------------------------\n",
      "Test AUC:       0.9334\n",
      "Test ACC:       0.8997\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Random Forest Model \n",
    "model_evaluation(\"Random Forest\", rf_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0005ffdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featura</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDEPEND</td>\n",
       "      <td>0.624743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NACCLIVS</td>\n",
       "      <td>0.047817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUC_YEARS</td>\n",
       "      <td>0.023181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NACCBMI_FLAG</td>\n",
       "      <td>0.023027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.022983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DEP2YRS_FLAG</td>\n",
       "      <td>0.022628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.022232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HEIGHT_FLAG</td>\n",
       "      <td>0.021008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WEIGHT_FLAG</td>\n",
       "      <td>0.020795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>INCONTU_FLAG</td>\n",
       "      <td>0.012988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         featura  importance\n",
       "4       INDEPEND    0.624743\n",
       "5       NACCLIVS    0.047817\n",
       "2     EDUC_YEARS    0.023181\n",
       "66  NACCBMI_FLAG    0.023027\n",
       "75           BMI    0.022983\n",
       "54  DEP2YRS_FLAG    0.022628\n",
       "0            AGE    0.022232\n",
       "67   HEIGHT_FLAG    0.021008\n",
       "68   WEIGHT_FLAG    0.020795\n",
       "72  INCONTU_FLAG    0.012988"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance(rf_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fbc59",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "Tune and train an XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0843eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "\n",
      "Best XGB Params: {'subsample': 0.7, 'reg_lambda': 1.5, 'reg_alpha': 0.01, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Best XGB CV AUC: 0.9293299171306252\n",
      "\n",
      "Best XGB Params: {'subsample': 0.7, 'reg_lambda': 1.5, 'reg_alpha': 0.01, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Best XGB CV AUC: 0.9293299171306252\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST PARAMETER SEARCH SPACE \n",
    "\n",
    "xgb_param_dist = {\n",
    "    \"n_estimators\": [300, 400, 500],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],\n",
    "    \"reg_lambda\": [1, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "# 2. Create base XGB model\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",     \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Randomized Search and final model training via helper\n",
    "\n",
    "xgb_final, rand_xgb = train_model(\n",
    "    base_estimator=xgb_base,\n",
    "    param_grid=xgb_param_dist,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    search_type=\"random\",\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_iter=40,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"\\nBest XGB Params:\", rand_xgb.best_params_)\n",
    "print(\"Best XGB CV AUC:\", rand_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06df8cb",
   "metadata": {},
   "source": [
    "## Evaluate XGBoost\n",
    "Evaluate performance of the tuned XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a1e149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "   XGBoost FINAL EVALUATION    \n",
      "====================================\n",
      "Validation AUC: 0.9369\n",
      "Validation ACC: 0.9034\n",
      "------------------------------------\n",
      "Test AUC:       0.9353\n",
      "Test ACC:       0.9006\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "#Evaluate XGB Model\n",
    "model_evaluation(\"XGBoost\", xgb_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8083ed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featura</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDEPEND</td>\n",
       "      <td>0.659126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DEP2YRS_FLAG</td>\n",
       "      <td>0.020632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEX</td>\n",
       "      <td>0.011914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NACCLIVS</td>\n",
       "      <td>0.010326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PD_FLAG</td>\n",
       "      <td>0.008522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.007311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RESIDENCE_4</td>\n",
       "      <td>0.007165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MARITAL_1</td>\n",
       "      <td>0.006914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QUITSMOK_FLAG</td>\n",
       "      <td>0.006728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RACE</td>\n",
       "      <td>0.006391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          featura  importance\n",
       "4        INDEPEND    0.659126\n",
       "54   DEP2YRS_FLAG    0.020632\n",
       "1             SEX    0.011914\n",
       "5        NACCLIVS    0.010326\n",
       "49        PD_FLAG    0.008522\n",
       "0             AGE    0.007311\n",
       "18    RESIDENCE_4    0.007165\n",
       "8       MARITAL_1    0.006914\n",
       "62  QUITSMOK_FLAG    0.006728\n",
       "20           RACE    0.006391"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance(xgb_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd078dfb",
   "metadata": {},
   "source": [
    "## CatBoost model\n",
    "Tune and train a CatBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e251f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "Best CatBoost Params: {'subsample': 1.0, 'learning_rate': 0.03, 'l2_leaf_reg': 9, 'iterations': 500, 'depth': 8, 'border_count': 254}\n",
      "Best CV AUC: 0.9292180753849003\n",
      "Best CatBoost Params: {'subsample': 1.0, 'learning_rate': 0.03, 'l2_leaf_reg': 9, 'iterations': 500, 'depth': 8, 'border_count': 254}\n",
      "Best CV AUC: 0.9292180753849003\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Search Space for CatBoost\n",
    "\n",
    "cat_param_dist = {\n",
    "    \"iterations\": [300, 500, 700, 900],\n",
    "    \"depth\": [4, 5, 6, 7, 8],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.07],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7, 9],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"border_count\": [32, 64, 128, 254]\n",
    "}\n",
    "\n",
    "# 2. Base CatBoost Model\n",
    "\n",
    "cat_base = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    "    \n",
    ")\n",
    "\n",
    "# 3. Random Search and final model training via helper\n",
    "\n",
    "cat_final, cat_search = train_model(\n",
    "    base_estimator=cat_base,\n",
    "    param_grid=cat_param_dist,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    search_type=\"random\",\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_iter=40,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Best CatBoost Params:\", cat_search.best_params_)\n",
    "print(\"Best CV AUC:\", cat_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e0b78",
   "metadata": {},
   "source": [
    "## Evaluate CatBoost\n",
    "Evaluate performance of the tuned CatBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c62271f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "   CatBoost FINAL EVALUATION    \n",
      "====================================\n",
      "Validation AUC: 0.9377\n",
      "Validation ACC: 0.9030\n",
      "------------------------------------\n",
      "Test AUC:       0.9367\n",
      "Test ACC:       0.9010\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "#Evaluate CatBoost Model\n",
    "model_evaluation(\"CatBoost\", cat_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bd2eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featura</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDEPEND</td>\n",
       "      <td>59.732510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>5.007252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUC_YEARS</td>\n",
       "      <td>3.587550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEX</td>\n",
       "      <td>2.430403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DEP2YRS_FLAG</td>\n",
       "      <td>2.170804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BMI</td>\n",
       "      <td>2.056276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NACCFAM_FLAG</td>\n",
       "      <td>1.963468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NACCLIVS</td>\n",
       "      <td>1.679306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WEIGHT_FLAG</td>\n",
       "      <td>1.449890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HEIGHT_FLAG</td>\n",
       "      <td>1.105655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         featura  importance\n",
       "4       INDEPEND   59.732510\n",
       "0            AGE    5.007252\n",
       "2     EDUC_YEARS    3.587550\n",
       "1            SEX    2.430403\n",
       "54  DEP2YRS_FLAG    2.170804\n",
       "75           BMI    2.056276\n",
       "76  NACCFAM_FLAG    1.963468\n",
       "5       NACCLIVS    1.679306\n",
       "68   WEIGHT_FLAG    1.449890\n",
       "67   HEIGHT_FLAG    1.105655"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance(cat_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1627c",
   "metadata": {},
   "source": [
    "## LightGBM model\n",
    "Tune and train a LightGBM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c05f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[LightGBM] [Info] Number of positive: 40434, number of negative: 95851\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 136285, number of used features: 79\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 40434, number of negative: 95851\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 136285, number of used features: 79\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 40434, number of negative: 95851\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 136285, number of used features: 79\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 40434, number of negative: 95851\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 136285, number of used features: 79\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Best LGBM Params: {'subsample': 1.0, 'reg_lambda': 0.5, 'reg_alpha': 0, 'num_leaves': 40, 'n_estimators': 800, 'max_depth': 8, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n",
      "Best LGBM CV AUC: 0.9290866050350829\n",
      "Best LGBM Params: {'subsample': 1.0, 'reg_lambda': 0.5, 'reg_alpha': 0, 'num_leaves': 40, 'n_estimators': 800, 'max_depth': 8, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n",
      "Best LGBM CV AUC: 0.9290866050350829\n"
     ]
    }
   ],
   "source": [
    "# 1. LightGBM Search Space\n",
    "\n",
    "lgb_param_dist = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"max_depth\": [-1, 4, 6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"num_leaves\": [20, 30, 40, 50, 60],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],\n",
    "    \"reg_lambda\": [0.1, 0.3, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# 2. Base Model\n",
    "\n",
    "lgb_base = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Randomized Search and final model training via helper\n",
    "\n",
    "lgb_final, lgb_search = train_model(\n",
    "    base_estimator=lgb_base,\n",
    "    param_grid=lgb_param_dist,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    search_type=\"random\",\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_iter=40,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Best LGBM Params:\", lgb_search.best_params_)\n",
    "print(\"Best LGBM CV AUC:\", lgb_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530d3ae",
   "metadata": {},
   "source": [
    "## Evaluate LightGBM\n",
    "Evaluate performance of the tuned LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ad82e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "   LightGBM FINAL EVALUATION    \n",
      "====================================\n",
      "Validation AUC: 0.9382\n",
      "Validation ACC: 0.9015\n",
      "------------------------------------\n",
      "Test AUC:       0.9362\n",
      "Test ACC:       0.8998\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "#Evaluate LightGBM Model\n",
    "model_evaluation(\"LightGBM\", lgb_final, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ba3fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featura</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>3197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUC_YEARS</td>\n",
       "      <td>2098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WEIGHT_FLAG</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDEPEND</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BMI</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HEIGHT_FLAG</td>\n",
       "      <td>1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NACCBMI_FLAG</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QUITSMOK_FLAG</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SMOKYRS_FLAG</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NACCFAM_FLAG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          featura  importance\n",
       "0             AGE        3197\n",
       "2      EDUC_YEARS        2098\n",
       "68    WEIGHT_FLAG        1855\n",
       "4        INDEPEND        1777\n",
       "75            BMI        1542\n",
       "67    HEIGHT_FLAG        1473\n",
       "66   NACCBMI_FLAG        1336\n",
       "62  QUITSMOK_FLAG        1255\n",
       "60   SMOKYRS_FLAG         926\n",
       "76   NACCFAM_FLAG         765"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance(lgb_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b8f3f",
   "metadata": {},
   "source": [
    "## Stacking ensemble\n",
    "Combine predictions from all four models using logistic regression as a meta model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b120f5",
   "metadata": {},
   "source": [
    "## Stacking ensemble\n",
    "Combine predictions from all four models using logistic regression as a meta model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "Validation AUC (4-Model Stacking): 0.9383\n",
      "============================================\n",
      "\n",
      "============================================\n",
      "Test AUC (4-Model Stacking): 0.937\n",
      "============================================\n",
      "\n",
      "============================================\n",
      "Test AUC (4-Model Stacking): 0.937\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# 1. Get PREDICTIONS for VALIDATION SET\n",
    "\n",
    "rf_val_proba  = rf_final.predict_proba(X_val)[:, 1]\n",
    "xgb_val_proba = xgb_final.predict_proba(X_val)[:, 1]\n",
    "lgb_val_proba = lgb_final.predict_proba(X_val)[:, 1]\n",
    "cat_val_proba = cat_final.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Build meta-feature matrix\n",
    "stack_val_X = np.column_stack([\n",
    "    rf_val_proba,\n",
    "    xgb_val_proba,\n",
    "    lgb_val_proba,\n",
    "    cat_val_proba\n",
    "])\n",
    "\n",
    "# 2. Train META-MODEL (Logistic Regression)\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "meta_model.fit(stack_val_X, y_val)\n",
    "\n",
    "# 3. Evaluate stacking on VALIDATION SET\n",
    "val_meta_proba = meta_model.predict_proba(stack_val_X)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_meta_proba)\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"Validation AUC (4-Model Stacking):\", round(val_auc, 4))\n",
    "print(\"============================================\")\n",
    "\n",
    "# 4. Get predictions on TEST SET\n",
    "rf_test_proba  = rf_final.predict_proba(X_test)[:, 1]\n",
    "xgb_test_proba = xgb_final.predict_proba(X_test)[:, 1]\n",
    "lgb_test_proba = lgb_final.predict_proba(X_test)[:, 1]\n",
    "cat_test_proba = cat_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Build test meta-feature set\n",
    "stack_test_X = np.column_stack([\n",
    "    rf_test_proba,\n",
    "    xgb_test_proba,\n",
    "    lgb_test_proba,\n",
    "    cat_test_proba\n",
    "])\n",
    "\n",
    "# 5. Final TEST SET prediction\n",
    "test_meta_proba = meta_model.predict_proba(stack_test_X)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_meta_proba)\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"Test AUC (4-Model Stacking):\", round(test_auc, 4))\n",
    "print(\"============================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
